---
id: ModuleEditor
title: Flow Context & Validation
displayed_sidebar: SDKSidebar
---

import NodeChip from '@site/src/components/NodeChip.js'


**ganymede_sdk.editor** contains classes for mimicking pipeline environment to facilitate debugging and to validate data schemas.

## `class` GanymedeContext

**GanymedeContext** stores _flow_ metadata such as user ID, input filenames, input parameters, and execution timestamp upon _flow_ execution.

### Attributes

- **run_id**: Timestamp in ms when _flow_ was kicked off for manually triggered flows; guaranteed to be unique per _flow_ run
- **created**: Timestamp in ms when _flow_ was kicked off for event-triggered flows
- **dag.dag_id**: name of _flow_
- **task_id**: type of _node_ (e.g. - <NodeChip text="Input_File" /> or <NodeChip text="Python" />)
- **params**: Run metadata; dictionary containing run_id, flow initiator, and file inputs to the flow.

### Methods

- **get_param(self, node_name: `str`, parameter_type: `str`) -> `str`**:
  - Obtain input parameter or input filename in _flow_. Node name can be found in the indigo bar at the top of each node. Parameter type generally references the file extension for nodes that ingest files, and can be found on the Flow Editor as values with green background and white text.
- **set_param(self, parameter_type: `str`, parameter_value: Any, node_name: `str` = None) -> None**:
  - Set parameter value

### Example

In the code below, the flow run timestamp, filename uploaded, and experiment_id flow input parameter are incorporated into the input CSV as new columns and written to the data lake.

```python
import pandas as pd
from typing import Union, Dict, List

def execute(
    df_sql_result: Union[pd.DataFrame, List[pd.DataFrame]], ganymede_context=None
) -> Union[pd.DataFrame, Dict[str, pd.DataFrame]]:
    """Add run_id and input parameter as columns to Pandas DataFrame
    """

    df_out = df_sql_result.copy()
    df_out['__run_id'] = ganymede_context.run_id
    df_out['__input_file_name'] = ganymede_context.get_param('CSV_Read', 'csv')
    df_out['experiment_id'] = ganymede_context.get_param('Input_Param', 'param')

    return df_out
```

## `class` MockGanymedeContext

**MockGanymedeContext** is used within editor notebooks to replicate the behavior of **GanymedeContext** in Editor notebooks, enabling users to test the behavior of code changes on data from prior runs.  When no parameters are passed into the object, calling **MockGanymedeContext()** with no parameters retrieves metadata from the most recent execution of the corresponding _flow_.  *MockGanymedeContext* has the same attributes as *GanymedeContext*.

### Example

```python
import pandas as pd
from ganymede_sdk.editor import GanymedeContext, MockGanymedeContext
from ganymede_sdk.io import retrieve_sql

query_sql = "SELECT * FROM input_table"

# User-editable Python function for node
def execute(df: pd.DataFrame, ganymede_context: GanymedeContext = None) -> pd.DataFrame:
  df['run_id'] = ganymede_context.run_id
  return df

# Use MockGanymedeContext object from most recent run in execute function
mock_ganymede_context = MockGanymedeContext()
df_input = retrieve_sql(query_sql)
df_output = execute(df_input, ganymede_context=mock_ganymede_context)
```

### Jinja templating for SQL Queries

Variables from the **GanymedeContext** can be used in SQL queries by using [Jinja templating](https://jinja.palletsprojects.com/en/3.0.x/templates/).  The full set of variables available for Jinja templates can be found in the params attribute of either the **GanymedeContext** or **MockGanymedeContext** objects.

The following example demonstrates how to use the **MockGanymedeContext** to retrieve data from the most recent run of a _flow_.

```python
from ganymede_sdk.editor import MockGanymedeContext
from ganymede_sdk.io import retrieve_sql

# Create MockGanymedeContext with inputs from most recent run
mock_ganymede_context = MockGanymedeContext()

# Retrieve dataframe with run_id from most recent run
query_sql = "SELECT * FROM tbl WHERE LEFT(run_id, 26) = FORMAT_TIMESTAMP("%Y-%m-%dT%R:%E6S", TIMESTAMP_MILLIS({{run_id}}))"
result = retrieve_sql(query_sql, context=mock_ganymede_context)
```

## `function` compare_df_to_table

*compare_df_to_table* allows users to compare the columns and schema on a Pandas DataFrame to a corresponding table in the Ganymede database.
The function returns differences in column names and data types between the DataFrame and the table, and can be used to validate that the DataFrame matches the table schema before writing the DataFrame to the table.

###  Parameters
- **ganymede_context** : `GanymedeContext`
    - Ganymede context to get run attributes
- **df** : `pd.DataFrame`
    - Pandas DataFrame to validate
- **table** : `str`
    - Name of table to compare DataFrame to
- **diffs_only**: `bool, optional, default=True`
    - If True, only return columns and schemas differences between DataFrame and table (rather than all columns and schemas in DataFrame and table)

```python
from ganymede_sdk.editor import GanymedeContext, compare_df_to_table

# use ganymede_context param if compare_df_to_table accessed inside of execute function
mock_ganymede_context = MockGanymedeContext()

# returns a Pandas DataFrame with schema and column
res = compare_df_to_table(mock_ganymede_context, df, 'ganymede_table_name')
```

The following examples are outputs from the *compare_df_to_table* function:

**Example:**

Pandas DataFrame named _df_plate_ with the following values:

| *well* | *run1* | *run2* |
|--------|--------|--------|
| A1     | 2.5    | 3.7    |
...

Table in Ganymede data lake named _plate_reader_run_ with the following values:

| *well* | *run1* | *run2* | *run_diff* |
|--------|--------|--------|------------|
| A1     | 2.5    | 4      | 1.5        |
...

Would result in the following DataFrames:

```python
# One column difference and one schema difference between DataFrame and table
compare_df_to_table(mock_ganymede_context, result_dfs, 'Example_Quickstart_Absorbance_Change_Python_results')
```

| *well* | *table_df* | *table_bq* | *diff* |
|--------|--------|--------|-----|
| run2     | FLOAT    | INT    | diff    |
| run_diff     | NaN    | FLOAT    | diff    |

```python
# Full set of schema and column differences between DataFrame and table returned
compare_df_to_table(mock_ganymede_context, result_dfs, 'Example_Quickstart_Absorbance_Change_Python_results', diffs_only=False)
```

| *well* | *table_df* | *table_bq* | *diff* |
|--------|--------|--------|-----|
| well     | STRING    | STRING    |   |
| run1     | FLOAT    | FLOAT    |   |
| run2     | FLOAT    | INT    | diff  |
| run_diff | NaN    | FLOAT    | diff   |
